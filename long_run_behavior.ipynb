{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c75cff-21b8-47dd-8426-272961cac725",
   "metadata": {},
   "source": [
    "# Extrapolating with a TS Model\n",
    "\n",
    "This notebook is meant to explore the long-run behavior of fitted time series models when extrapolating into the future, or \"forecasting\". We distinguish a \"fitted\" model from the underlying statistical process where you are not introducing new noise and simply extrapolating the deterministic component of the model. The limiting behavior of the processes is related to whether it is stationary.\n",
    "\n",
    "This notebook adds mathematical clarity to the other notebook on forecasting with an ARX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e4ffd-0f57-44b0-9b2a-e4a437b6ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from ts_tools import sim_arma, plot_ts, plt_acf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6846cb35-bad0-4904-a107-c89e43cb9fea",
   "metadata": {},
   "source": [
    "## Pure MA Process\n",
    "\n",
    "### Stationarity\n",
    "\n",
    "The pure MA processes with a constant mean is **always stationary**. An MA(q) processes is defined as:\n",
    "\n",
    "$$\n",
    "z_t = \\mu+ \\sum_{i=0}^q\\theta_i\\epsilon_{t-i}, \\quad\\epsilon_t \\overset{\\text{i.i.d.}}{\\sim}  N(0,\\sigma^2)\n",
    "$$\n",
    "\n",
    "Where $\\theta_0 = 1$, we define it in one sum to make the autocovariance derivation easier. \n",
    "\n",
    "The expected value and variance are constant for the process:\n",
    "\n",
    "$$\n",
    "E[z_t] = \\mu\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Var[z_t] &= Var[\\mu] + \\sum_{i=0}^q Var[\\theta_i\\epsilon_{t-i}] \\\\\n",
    "&= \\sigma^2 \\sum_{i=0}^q \\theta_i^2 \\\\\n",
    "&= \\sigma^2(1+\\sum_{i=1}^q \\theta_i^2)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The autocovariance function is a bit tedious to derive, as it involves lining up the indices of the coefficient terms for appropriate lags. The ACF ends up as a function of lag $k$, not of time:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Cov[z_t, z_{t-k}] &= Cov\\left[\\mu+ \\sum_{i=1}^q\\theta_i\\epsilon_{t-i} +\\epsilon_t, \\mu+ \\sum_{i=1}^q\\theta_i\\epsilon_{t-i-k} +\\epsilon_{t-k}\\right] \\\\ \n",
    "&= \n",
    "\\begin{cases} \n",
    "    \\sigma^2\\sum_{i=0}^q \\theta_i\\theta_{i-k} &\\text{ for } 0\\leq k \\leq q \\\\\n",
    "    0 &\\text{ for } k > q\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "These properties combine to show weak stationarity (it's also strong stationary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d64bbad-2872-4101-b61d-03a715fd7a6f",
   "metadata": {},
   "source": [
    "### Extrapolation with Fitted MA Model\n",
    "\n",
    "We describe the behavior of a MA(1) model. The general MA(q) extends these concepts straightforwardly. Consider an MA(1) model:\n",
    "\n",
    "$$\n",
    "y_t = \\mu + \\theta\\epsilon_{t-1}+\\epsilon_t\n",
    "$$\n",
    "\n",
    "We estimate the coefficients with sample time series $y_1, \\dots, y_N$. We wish to extrapolate the model forward without introducing new noise. The estimated extrapolated value one time step in the future is generated using the residual from the previous time step. The current $\\epsilon_t$ value is set to zero:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat y_{N+1} &= \\hat \\mu + \\hat \\theta \\hat \\epsilon_{t-1} \\\\\n",
    "&= \\hat \\mu + \\hat\\theta (y_N - \\hat y_N)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "So we can use the residual calculated by comparing the fitted values of the model to the observed values. For the next forecasted value, we have:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat y_{N+2} &= \\hat \\mu + \\hat\\theta \\hat \\epsilon_{N+1}\\\\\n",
    "&= \\hat \\mu\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "But we assumed that we generated $y_{N+1}$ with zero additional noise, so the modeling error at $N+1$ is assumed to be zero. Thus, after 1 time step into the future, all of the forecasts decay to the estimated mean $\\hat \\mu$. For a general MA(q) process, the forecasts decay to the estimated mean after $q$ steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5360176-cbe8-4233-8c91-16ad8b10a63c",
   "metadata": {},
   "source": [
    "### Simulations\n",
    "\n",
    "We simulate a mean-zero MA(3) process with known coefficients, then fit a model to estimate the coefficients, and finally extrapolate/forecast the model into the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee245831-9288-4b6b-a9d0-5400a4fd8f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "Nt = 100 \n",
    "z = sim_arma(n=Nt, ma_coefs = [1, 0.8, 0.6, 0.4])\n",
    "plot_ts(z, title=\"MA(3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b87148-3b18-473d-b4f1-2f2ef8ad4cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_acf(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2f66c-c06a-48b7-977d-1d1202fc1f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma3 = ARIMA(z, order=(0, 0, 3)).fit() # MA(1)\n",
    "ma3.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1765761e-957f-470c-b8a1-8c3ee19d6b95",
   "metadata": {},
   "source": [
    "The ACF plot shows 3 significant non-zero lags, as expected. The fitted model coefficients are relatively close to the target values. The estimated mean is the value that the extrapolated series will converge to. When forecasting, the values decay to the mean of zero after 3 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c2891-9b06-4369-bc27-a5eb144cc3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nf = 30\n",
    "fits = ma3.fittedvalues\n",
    "preds = ma3.forecast(steps=Nf)\n",
    "\n",
    "plt.title(\"Fitted MA(3) Long Run Behavior\")\n",
    "plt.plot(np.concatenate([fits, preds]))\n",
    "plt.axvline(x = Nt, linestyle=\"dashed\", color=\"k\")\n",
    "plt.text(Nt, 2, 'Forecast Start', rotation=90,\n",
    "         verticalalignment='center', horizontalalignment='right',\n",
    "         color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7c137-6e6f-4647-aa56-c23e8051c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nf = 12\n",
    "fits = ma3.fittedvalues\n",
    "preds = ma3.forecast(steps=Nf)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "\n",
    "axs[0].plot(np.concatenate([fits, preds]))\n",
    "axs[0].axvline(x = Nt, linestyle=\"dashed\", color=\"k\", alpha=.7)\n",
    "axs[0].text(Nt, 2, 'Forecast Start', rotation=90,\n",
    "         verticalalignment='center', horizontalalignment='right',\n",
    "         color='k', fontsize=8, alpha=.7)\n",
    "\n",
    "axs[1].plot(np.concatenate([preds]))\n",
    "axs[1].set_ylim(-1, 1)\n",
    "axs[1].axvline(x = 0, linestyle=\"dashed\", color=\"k\", alpha=.7)\n",
    "axs[1].axvline(x = 3, linestyle=\"dashed\", color=\"k\", alpha=.7)\n",
    "axs[1].text(3, 0.5, 'Time N+3', rotation=90,\n",
    "         verticalalignment='center', horizontalalignment='right',\n",
    "         color='k', fontsize=8, alpha=.7)\n",
    "xticks = np.linspace(0, Nf, 5)\n",
    "axs[1].set_xticks(xticks)\n",
    "axs[1].set_xticklabels([str(int(tick + Nt)) for tick in xticks])\n",
    "\n",
    "fig.suptitle(\"Fitted MA(3) Long Run Behavior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b5b5ee-e9ee-4474-89bd-5fcf50b51818",
   "metadata": {},
   "source": [
    "## Pure AR Models\n",
    "\n",
    "Autoregressive models can have 3 types of long range behavior when forecasted into the future with no new sources of noise:\n",
    "\n",
    "1. Converge to a finite value (weakly stationary)\n",
    "2. Diverge to +/- infinity, or oscillate to those extremes\n",
    "3. A Random Gaussian Walk\n",
    "\n",
    "These behaviors can be shown when examining the mean of the processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7cd34-6c32-4aa9-995a-5a9209f6318f",
   "metadata": {},
   "source": [
    "### Stationarity\n",
    "\n",
    "We consider an AR(1) processes, but the concept extends to general AR(p) processes straightforwardly. The AR(1) process is defined as:\n",
    "\n",
    "$$\n",
    "y_t = \\mu + \\gamma y_{t-1} + \\epsilon_t, \\quad\\epsilon_t \\overset{\\text{i.i.d.}}{\\sim}  N(0,\\sigma^2)\n",
    "$$\n",
    "\n",
    "The derivation of the mean involves an infinite recursive relationship, and then can be analyzed using the convergence properties for geometric series:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    E[y_t] &= E[\\mu + \\gamma y_{t-1}+\\epsilon_t] \\\\ \n",
    "    &= \\mu + \\gamma E[y_{t-1}] \\\\\n",
    "    & = \\mu + \\gamma \\mu + \\gamma E[y_{t-2}] \\\\\n",
    "    \\vdots\\\\\n",
    "    & = \\mu \\left(\\sum_{j=0}^\\infty \\gamma^j\\right)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01988cd-ddbd-4cd7-8845-6ecd86156762",
   "metadata": {},
   "source": [
    "For $|\\gamma|<1$, the series converges, and the mean of the process is the constant value:\n",
    "\n",
    "$$\n",
    "E[y_t] = \\frac{\\mu}{1-\\gamma}, \\quad |\\gamma|<1\n",
    "$$\n",
    "\n",
    "For $|\\gamma|>1$, the series diverges to plus or minus infinity, possible with oscillatory behavior if $\\gamma$ is negative. \n",
    "\n",
    "For $|\\gamma|=1$ the series also does not converge, so the mean is undefined. \n",
    "\n",
    "\n",
    "For completion, we will show the weak-stationarity conditions for the situation where $|\\gamma|<1$. The variance ends up constant and is derived similarly as the mean:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    V[y_t] &= V[\\mu + \\gamma y_{t-1}+\\epsilon_t] \\\\ \n",
    "    &= \\sigma^2 + \\gamma^2 V[y_{t-1}] \\\\\n",
    "    & = \\sigma^2 + \\gamma \\sigma^2 + \\gamma V[y_{t-2}] \\\\\n",
    "    \\vdots\\\\\n",
    "    & = \\sigma^2 \\left(\\sum_{j=0}^\\infty (\\gamma^2)^j\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This series converges for $|\\gamma^2|<1$, or simply $|\\gamma|<1$ as before, and the variance is the constant value:\n",
    "\n",
    "$$\n",
    "V[y_t] = \\frac{\\sigma^2}{1-\\gamma^2}, \\quad |\\gamma|<1\n",
    "$$\n",
    "\n",
    "Similarly, the autocovariance ends up only as a function of lag. We show the derivation for a couple of timesteps and then deduce the pattern:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    Cov[y_t, y_{t-1}] &= Cov[\\mu + \\gamma y_{t-1}+\\epsilon_t, y_{t-1} \\\\\n",
    "    & = \\gamma Cov[y_{t-1}, y_{t-1}] \\\\\n",
    "    & = \\gamma Var[y_t]\\\\\n",
    "    & = \\gamma \\frac{\\sigma^2}{1-\\gamma^2}, \\quad |\\gamma|<1\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    Cov[y_t, y_{t-2}] &= Cov[\\mu + \\gamma y_{t-1}+\\epsilon_t, y_{t-2} \\\\\n",
    "    & = Cov[\\mu + \\gamma^2 y_{t-2}+..., y_{t-2}\n",
    "    & = \\gamma^2 Cov[y_{t-2}, y_{t-2}] \\\\\n",
    "    & = \\gamma^2 Var[y_t]\\\\\n",
    "    & = \\gamma^2 \\frac{\\sigma^2}{1-\\gamma^2}, \\quad |\\gamma|<1\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "And,\n",
    "$$\n",
    "Cov(y_t, y_{t-k})= \\gamma^k \\frac{\\sigma^2}{1-\\gamma^2}, \\quad |\\gamma|<1\n",
    "$$\n",
    "\n",
    "These properties combined show that the AR(1) process is stationary for coefficient $|\\gamma|<1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c0ce1-56b1-4794-800f-acfef957d764",
   "metadata": {},
   "source": [
    "### Case 1: Stationary Process Converges to Equilibrium\n",
    "\n",
    "We simulate a mean zero AR(1) with autoregressive coefficient less than one in absolute terms. The forecast decays to zero at a rate relative to the absolute value of the coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b678267-7c34-49a5-8936-a4c8ab7ecff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "Nt = 100 \n",
    "z = sim_arma(n=Nt, ar_coefs = [1, 0.8])\n",
    "plot_ts(z, title=\"AR(1), $y_t = -0.8y_{t-1}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc97b2-09e0-46a2-8422-17a7db5677d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_acf(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9a7a7-e430-4ddb-9928-d949e8b69415",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1 = ARIMA(z, order=(1, 0, 0)).fit() # AR(1)\n",
    "ar1.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f790a-9d77-4aeb-b699-7c0b59ddc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nf = 20\n",
    "fits = ar1.fittedvalues\n",
    "preds = ar1.forecast(steps=Nf)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "\n",
    "axs[0].plot(np.concatenate([fits, preds]))\n",
    "axs[0].axvline(x = Nt, linestyle=\"dashed\", color=\"k\", alpha=.7)\n",
    "axs[0].text(Nt, 2, 'Forecast Start', rotation=90,\n",
    "         verticalalignment='center', horizontalalignment='right',\n",
    "         color='k', fontsize=8, alpha=.7)\n",
    "\n",
    "axs[1].plot(np.concatenate([preds]))\n",
    "axs[1].set_ylim(-1, 1)\n",
    "axs[1].axvline(x = 0, linestyle=\"dashed\", color=\"k\", alpha=.7)\n",
    "xticks = np.linspace(0, Nf, 6)\n",
    "axs[1].set_xticks(xticks)\n",
    "axs[1].set_xticklabels([str(int(tick + Nt)) for tick in xticks])\n",
    "\n",
    "fig.suptitle(\"Fitted AR(1) Long Run Behavior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f7d5a-3f10-479b-be6f-5408bfe6d237",
   "metadata": {},
   "source": [
    "### Case 2: Diverges to +/- Infinity\n",
    "\n",
    "We simulate a mean zero AR(1) with autoregressive coefficient greater than one in absolute terms. The simulations explode to +/- infinity, oscillating for the negative coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d897457-3591-4bbc-b1fb-1b210990003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "Nt = 30\n",
    "z1 = sim_arma(n=Nt, ar_coefs = [1, -1.5])\n",
    "z2 = sim_arma(n=Nt, ar_coefs = [1, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec20cb1-2c7f-4c71-af7d-22e1f27e0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ts(z1, title=\"AR(1), $y_t = 1.5y_{t-1}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adcf2c5-ba79-4235-a961-b88556c63a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ts(z2, title=\"AR(1), $y_t = -1.5y_{t-1}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c02dd6f-dcce-4d6a-84f0-f3f4ff94d5cd",
   "metadata": {},
   "source": [
    "### Case 3: Gaussian Random Walk\n",
    "\n",
    "With $|\\gamma|=1$, the process is:\n",
    "\n",
    "$$\n",
    "y_t = y_{t-1} + \\epsilon_t, \\quad \\epsilon_t \\sim N(0,\\sigma^2)\n",
    "$$\n",
    "\n",
    "This is a type of statistical random walk, where at each time you step up or down by an amount determined by a sample from a Gaussian random variable. This can also be thought of as the discrete time approximation of Brownian Motion. \n",
    "\n",
    "We can analyze the mean and variance of the processes starting from an initial value of $y_0=0$. Note: this was possible to do in the other cases, but less informative. The mean of the process ends up being the initial value, and the variance grows with time:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    E[y_t] &= E[y_{t-1}+\\epsilon_t]\\\\\n",
    "    &= E[y_{t-2}+\\epsilon_{t-1}] \\\\\n",
    "    & \\vdots \\\\\n",
    "    &= E[y_0] = 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    V[y_t] &= V[y_{t-1}+\\epsilon_t]\\\\\n",
    "    &= V[t-1]+\\sigma^2\\\\\n",
    "    &= V[t-2]+2\\sigma^2\\\\\n",
    "    & \\vdots \\\\\n",
    "    &= t\\sigma^2\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We will simulate several realizations with $\\gamma=1$, starting from the same initial state of zero. Gaussian Random walks are strange. It can be shown that a Gaussian Random walk is *recurrent*, in that it will revisit its starting location infinitely many times, but the expected recurrence time is infinite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e5811-e90f-4005-89ba-345848dbdfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "Nt = 100\n",
    "nsims=10\n",
    "\n",
    "for i in range(0, nsims):\n",
    "    z = sim_arma(n=Nt, ar_coefs = [1, -1])\n",
    "    plt.plot(z)\n",
    "\n",
    "plt.grid()\n",
    "plt.title(\"Gaussian Random Walk, $y_t = y_{t-1}+\\\\epsilon_t$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c4b43-55b9-4f4e-8068-5bd524b9ea6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8bcacc-64de-4623-8e3d-d3f32e17fc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b13274-39fc-4237-9f32-7510c64b50f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
